{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1004)\n",
      "(?,)\n",
      "()\n",
      "(Iteration 20 / 125042) loss: 6.872166, and time eclipsed: 0.15 minutes\n",
      "(Iteration 40 / 125042) loss: 4.350332, and time eclipsed: 0.30 minutes\n",
      "(Iteration 60 / 125042) loss: 4.295280, and time eclipsed: 0.47 minutes\n",
      "(Iteration 80 / 125042) loss: 4.247094, and time eclipsed: 0.63 minutes\n",
      "(Iteration 100 / 125042) loss: 4.173530, and time eclipsed: 0.80 minutes\n",
      "(Iteration 120 / 125042) loss: 3.948173, and time eclipsed: 0.97 minutes\n",
      "(Iteration 140 / 125042) loss: 3.754292, and time eclipsed: 1.12 minutes\n",
      "(Iteration 160 / 125042) loss: 3.612969, and time eclipsed: 1.30 minutes\n",
      "(Iteration 180 / 125042) loss: 3.531831, and time eclipsed: 1.45 minutes\n",
      "(Iteration 200 / 125042) loss: 3.614957, and time eclipsed: 1.60 minutes\n",
      "(Iteration 220 / 125042) loss: 3.837688, and time eclipsed: 1.75 minutes\n",
      "(Iteration 240 / 125042) loss: 3.184744, and time eclipsed: 1.90 minutes\n",
      "(Iteration 260 / 125042) loss: 3.121167, and time eclipsed: 2.05 minutes\n",
      "(Iteration 280 / 125042) loss: 3.429667, and time eclipsed: 2.22 minutes\n",
      "(Iteration 300 / 125042) loss: 3.254844, and time eclipsed: 2.38 minutes\n",
      "(Iteration 320 / 125042) loss: 3.201999, and time eclipsed: 2.55 minutes\n",
      "(Iteration 340 / 125042) loss: 3.309383, and time eclipsed: 2.70 minutes\n",
      "(Iteration 360 / 125042) loss: 3.279721, and time eclipsed: 2.87 minutes\n",
      "(Iteration 380 / 125042) loss: 3.548399, and time eclipsed: 3.00 minutes\n",
      "(Iteration 400 / 125042) loss: 3.124251, and time eclipsed: 3.13 minutes\n",
      "(Iteration 420 / 125042) loss: 3.179727, and time eclipsed: 3.30 minutes\n",
      "(Iteration 440 / 125042) loss: 3.308524, and time eclipsed: 3.43 minutes\n",
      "(Iteration 460 / 125042) loss: 3.188917, and time eclipsed: 3.58 minutes\n",
      "(Iteration 480 / 125042) loss: 3.117469, and time eclipsed: 3.73 minutes\n",
      "(Iteration 500 / 125042) loss: 3.100524, and time eclipsed: 3.90 minutes\n",
      "(Iteration 520 / 125042) loss: 2.932375, and time eclipsed: 4.07 minutes\n",
      "(Iteration 540 / 125042) loss: 2.867708, and time eclipsed: 4.20 minutes\n",
      "(Iteration 560 / 125042) loss: 2.905267, and time eclipsed: 4.35 minutes\n",
      "(Iteration 580 / 125042) loss: 2.958122, and time eclipsed: 4.48 minutes\n",
      "(Iteration 600 / 125042) loss: 3.041101, and time eclipsed: 4.62 minutes\n",
      "(Iteration 620 / 125042) loss: 2.729964, and time eclipsed: 4.77 minutes\n",
      "(Iteration 640 / 125042) loss: 2.969045, and time eclipsed: 4.90 minutes\n",
      "(Iteration 660 / 125042) loss: 3.021488, and time eclipsed: 5.05 minutes\n",
      "(Iteration 680 / 125042) loss: 3.125349, and time eclipsed: 5.17 minutes\n",
      "(Iteration 700 / 125042) loss: 2.824711, and time eclipsed: 5.32 minutes\n",
      "(Iteration 720 / 125042) loss: 3.083382, and time eclipsed: 5.48 minutes\n",
      "(Iteration 740 / 125042) loss: 3.128969, and time eclipsed: 5.62 minutes\n",
      "(Iteration 760 / 125042) loss: 2.923647, and time eclipsed: 5.78 minutes\n",
      "(Iteration 780 / 125042) loss: 2.962772, and time eclipsed: 5.93 minutes\n",
      "(Iteration 800 / 125042) loss: 2.834918, and time eclipsed: 6.10 minutes\n",
      "(Iteration 820 / 125042) loss: 2.813288, and time eclipsed: 6.25 minutes\n",
      "(Iteration 840 / 125042) loss: 3.114624, and time eclipsed: 6.40 minutes\n",
      "(Iteration 860 / 125042) loss: 2.832283, and time eclipsed: 6.58 minutes\n",
      "(Iteration 880 / 125042) loss: 2.365661, and time eclipsed: 6.75 minutes\n",
      "(Iteration 900 / 125042) loss: 2.851162, and time eclipsed: 6.90 minutes\n",
      "(Iteration 920 / 125042) loss: 3.107908, and time eclipsed: 7.05 minutes\n",
      "(Iteration 940 / 125042) loss: 2.660531, and time eclipsed: 7.18 minutes\n",
      "(Iteration 960 / 125042) loss: 2.942513, and time eclipsed: 7.35 minutes\n",
      "(Iteration 980 / 125042) loss: 3.027692, and time eclipsed: 7.50 minutes\n",
      "(Iteration 1000 / 125042) loss: 2.949410, and time eclipsed: 7.65 minutes\n",
      "(Iteration 1020 / 125042) loss: 3.015490, and time eclipsed: 7.83 minutes\n",
      "(Iteration 1040 / 125042) loss: 3.101913, and time eclipsed: 7.98 minutes\n",
      "(Iteration 1060 / 125042) loss: 2.969039, and time eclipsed: 8.15 minutes\n",
      "(Iteration 1080 / 125042) loss: 3.206784, and time eclipsed: 8.30 minutes\n",
      "(Iteration 1100 / 125042) loss: 2.627946, and time eclipsed: 8.45 minutes\n",
      "(Iteration 1120 / 125042) loss: 3.081509, and time eclipsed: 8.60 minutes\n",
      "(Iteration 1140 / 125042) loss: 3.197126, and time eclipsed: 8.73 minutes\n",
      "(Iteration 1160 / 125042) loss: 2.790049, and time eclipsed: 8.90 minutes\n",
      "(Iteration 1180 / 125042) loss: 2.883499, and time eclipsed: 9.03 minutes\n",
      "(Iteration 1200 / 125042) loss: 2.964952, and time eclipsed: 9.17 minutes\n",
      "(Iteration 1220 / 125042) loss: 2.586555, and time eclipsed: 9.35 minutes\n",
      "(Iteration 1240 / 125042) loss: 3.119862, and time eclipsed: 9.53 minutes\n",
      "(Iteration 1260 / 125042) loss: 3.024754, and time eclipsed: 9.72 minutes\n",
      "(Iteration 1280 / 125042) loss: 3.034333, and time eclipsed: 9.88 minutes\n",
      "(Iteration 1300 / 125042) loss: 3.026576, and time eclipsed: 10.05 minutes\n",
      "(Iteration 1320 / 125042) loss: 3.279510, and time eclipsed: 10.22 minutes\n",
      "(Iteration 1340 / 125042) loss: 3.110724, and time eclipsed: 10.37 minutes\n",
      "(Iteration 1360 / 125042) loss: 2.976618, and time eclipsed: 10.55 minutes\n",
      "(Iteration 1380 / 125042) loss: 2.906768, and time eclipsed: 10.70 minutes\n",
      "(Iteration 1400 / 125042) loss: 2.672922, and time eclipsed: 10.87 minutes\n",
      "(Iteration 1420 / 125042) loss: 2.932565, and time eclipsed: 11.02 minutes\n",
      "(Iteration 1440 / 125042) loss: 2.734643, and time eclipsed: 11.17 minutes\n",
      "(Iteration 1460 / 125042) loss: 2.704440, and time eclipsed: 11.33 minutes\n",
      "(Iteration 1480 / 125042) loss: 2.919254, and time eclipsed: 11.48 minutes\n",
      "(Iteration 1500 / 125042) loss: 2.612199, and time eclipsed: 11.63 minutes\n",
      "(Iteration 1520 / 125042) loss: 2.911607, and time eclipsed: 11.82 minutes\n",
      "(Iteration 1540 / 125042) loss: 2.939571, and time eclipsed: 11.98 minutes\n",
      "(Iteration 1560 / 125042) loss: 2.901143, and time eclipsed: 12.15 minutes\n",
      "(Iteration 1580 / 125042) loss: 2.377409, and time eclipsed: 12.30 minutes\n",
      "(Iteration 1600 / 125042) loss: 2.766465, and time eclipsed: 12.45 minutes\n",
      "(Iteration 1620 / 125042) loss: 2.282959, and time eclipsed: 12.62 minutes\n",
      "(Iteration 1640 / 125042) loss: 2.452294, and time eclipsed: 12.78 minutes\n",
      "(Iteration 1660 / 125042) loss: 2.464637, and time eclipsed: 12.98 minutes\n",
      "(Iteration 1680 / 125042) loss: 2.924283, and time eclipsed: 13.13 minutes\n",
      "(Iteration 1700 / 125042) loss: 2.612820, and time eclipsed: 13.30 minutes\n",
      "(Iteration 1720 / 125042) loss: 2.256271, and time eclipsed: 13.47 minutes\n",
      "(Iteration 1740 / 125042) loss: 2.835533, and time eclipsed: 13.63 minutes\n",
      "(Iteration 1760 / 125042) loss: 2.672409, and time eclipsed: 13.78 minutes\n",
      "(Iteration 1780 / 125042) loss: 2.489495, and time eclipsed: 13.93 minutes\n",
      "(Iteration 1800 / 125042) loss: 2.403631, and time eclipsed: 14.07 minutes\n",
      "(Iteration 1820 / 125042) loss: 2.572525, and time eclipsed: 14.20 minutes\n",
      "(Iteration 1840 / 125042) loss: 2.436391, and time eclipsed: 14.33 minutes\n",
      "(Iteration 1860 / 125042) loss: 2.234955, and time eclipsed: 14.47 minutes\n",
      "(Iteration 1880 / 125042) loss: 2.875128, and time eclipsed: 14.60 minutes\n",
      "(Iteration 1900 / 125042) loss: 2.492932, and time eclipsed: 14.75 minutes\n",
      "(Iteration 1920 / 125042) loss: 2.294955, and time eclipsed: 14.88 minutes\n",
      "(Iteration 1940 / 125042) loss: 2.881751, and time eclipsed: 15.05 minutes\n",
      "(Iteration 1960 / 125042) loss: 2.583134, and time eclipsed: 15.22 minutes\n",
      "(Iteration 1980 / 125042) loss: 3.232096, and time eclipsed: 15.38 minutes\n",
      "(Iteration 2000 / 125042) loss: 2.663523, and time eclipsed: 15.57 minutes\n",
      "(Iteration 2020 / 125042) loss: 2.784364, and time eclipsed: 15.75 minutes\n",
      "(Iteration 2040 / 125042) loss: 2.802791, and time eclipsed: 15.95 minutes\n",
      "(Iteration 2060 / 125042) loss: 2.723883, and time eclipsed: 16.13 minutes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b2e973c854a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-6b2e973c854a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6b2e973c854a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, config, data)\u001b[0m\n\u001b[1;32m    263\u001b[0m                         model.caption_out: caption_out, model.caption_mask: mask}\n\u001b[1;32m    264\u001b[0m             merge_op, _, total_loss, learning = sess.run([model.summary_op, train_op, model.total_loss, learning_change],\n\u001b[0;32m--> 265\u001b[0;31m                                            feed_dict = feed_dict)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amber/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amber/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amber/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/amber/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amber/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# coding: utf-8\n",
    "# coding: utf-8\n",
    "\n",
    "# In[34]:\n",
    "from datetime import datetime \n",
    "import tensorflow as tf\n",
    "from coco_utils import load_coco_data, decode_captions\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from image_utils import image_from_url, write_text_on_image\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.vocab_size =1004\n",
    "        self.batch_size = 32\n",
    "        self.initializer_scale =0.08\n",
    "        self.H = 512 #hidden dimension\n",
    "        self.T = 16 # caption length\n",
    "        self.feature_len = 512\n",
    "        self.W = 512 # embedding size\n",
    "        self.num_epochs_per_decay = 1\n",
    "        self.total_instances = 400135\n",
    "        self.initial_learning_rate = 2.0\n",
    "        self.input_len = 16\n",
    "        self.clip_gradients = 5.0\n",
    "        self.num_epochs = 10\n",
    "        self.num_of_layers = 1\n",
    "\n",
    "def _run_validation(sess, caption_in, caption_out,features, batch_size, model, T):\n",
    "    \"\"\"\n",
    "    Make a single gradient update for batch data. \n",
    "    \"\"\"\n",
    "    # Make a minibatch of training data\n",
    "    \n",
    "    captions_in = caption_in[:, 0].reshape(-1, 1)\n",
    "    \n",
    "    state = None \n",
    "    final_preds = []\n",
    "    current_pred = captions_in\n",
    "    mask = np.zeros((batch_size, 1))\n",
    "    mask[:, 0] = 1\n",
    "    \n",
    "    # get initial state using image feature \n",
    "    feed_dict = {model.image_feature: features}\n",
    "    state = sess.run(model.initial_state, feed_dict=feed_dict)\n",
    "    \n",
    "    # start to generate sentences\n",
    "    val_loss = 0\n",
    "    for t in range(T):\n",
    "        \n",
    "        feed_dict={model.caption_in: current_pred, \n",
    "                   model.initial_state : state, \n",
    "                   model.caption_mask: mask,\n",
    "                   model.caption_out: caption_out[:,t].reshape(-1,1)}\n",
    "        loss = None    \n",
    "       \n",
    "        current_pred, state, loss = sess.run([model.preds, model.final_state, model.total_loss], feed_dict=feed_dict)\n",
    "\n",
    "       \n",
    "        val_loss += loss\n",
    "        current_pred = current_pred.reshape(-1, 1)   \n",
    "        final_preds.append(current_pred)\n",
    "        \n",
    "    val_loss /= T\n",
    "    sum_op = tf.summary.scalar(\"val-loss\", val_loss)\n",
    "    return final_preds, val_loss,sum_op\n",
    "\n",
    "def minibatch(data, index, batch_size,total_size, split='train'):\n",
    "    #batch_size = batch_size+1\n",
    "    begin = batch_size*index%total_size\n",
    "    end = begin+ batch_size\n",
    "    if end > total_size:\n",
    "        print(begin)\n",
    "        end = end - total_size# minus sign\n",
    "        caption_end = data['%s_captions'%split][begin:]\n",
    "        caption_first = data['%s_captions'%split][:end]\n",
    "        image_idxs_end = data['%s_image_idxs'%split][:end]\n",
    "        image_idxs_first = data['%s_image_idxs'%split][begin:]\n",
    "        image_idxs = np.append(image_idxs_end, image_idxs_first, axis=0)\n",
    "        caption = np.append(caption_end, caption_first,axis=0)\n",
    "    else:\n",
    "        caption = data['%s_captions'%split][begin:end]\n",
    "        image_idxs = data['%s_image_idxs'%split][begin:end]\n",
    "    \n",
    "    image_features = data['%s_features' % split][image_idxs]\n",
    "    urls = data['%s_urls' % split][image_idxs]\n",
    "    caption_in = caption[:,:-1]\n",
    "    caption_out = caption[:,1:]\n",
    "    mask = (caption_out != 0)\n",
    "    \n",
    "    return caption_in, caption_out, mask, image_features, urls\n",
    "\n",
    "        \n",
    "class LSTM_Model:\n",
    "    def __init__(self, mode, config):\n",
    "        self.config = config\n",
    "        self.initializer = tf.random_uniform_initializer(\n",
    "            minval=-self.config.initializer_scale,\n",
    "            maxval=self.config.initializer_scale)\n",
    "        self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\"global_step\")        \n",
    "        #Mode can be \"train\", \"test\", \"infer\"\n",
    "        #assert error if the mode is not one of the three predesigned modes.\n",
    "#         assert mode in ['train','test','infer']\n",
    "#     def is_training(self):\n",
    "#         return self.mode == \"train\"\n",
    "  \n",
    "    def _build_embedding(self):\n",
    "        with tf.variable_scope(\"word_embedding\"):\n",
    "            self.caption_in = tf.placeholder(tf.int32,[self.config.batch_size, None], name=\"caption_in\")\n",
    "            self.embed_map = tf.get_variable(name=\"embed_map\", \n",
    "                                           shape=[self.config.vocab_size, self.config.W],\n",
    "                                           initializer = self.initializer)\n",
    "            word_vectors = tf.nn.embedding_lookup(self.embed_map, self.caption_in)\n",
    "        self.word_embedding = word_vectors\n",
    "        \n",
    "        with tf.variable_scope(\"image_embedding\"):\n",
    "            self.image_feature = tf.placeholder(tf.float32,[self.config.batch_size, self.config.feature_len], name=\"image_feature\")\n",
    "            feature_embedding = tf.contrib.layers.fully_connected(\n",
    "            inputs=self.image_feature,\n",
    "            num_outputs= self.config.H,\n",
    "            activation_fn=None,\n",
    "            weights_initializer= self.initializer,\n",
    "            biases_initializer=None)\n",
    "        \n",
    "        self.feature_embedding = feature_embedding\n",
    "    \n",
    "    def _build_model(self):\n",
    "        #self.mode = tf.placeholder(tf.string, name='mode')\n",
    "        lstm_cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "            num_units = self.config.H, state_is_tuple =True)\n",
    "        lstm_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell] *self.config.num_of_layers)\n",
    "\n",
    "        # drop out is not included\n",
    "        with tf.variable_scope(\"lstm\", initializer = self.initializer) as lstm_scope:\n",
    "            self.caption_out = tf.placeholder(tf.int32,[self.config.batch_size, None], name=\"caption_out\")\n",
    "            self.caption_mask = tf.placeholder(tf.int32,[self.config.batch_size, None], name=\"caption_mask\")\n",
    "            zero_state = lstm_cell.zero_state(\n",
    "                batch_size=self.config.batch_size,dtype=tf.float32)\n",
    "            _, self.initial_state = lstm_cell(self.feature_embedding, zero_state)\n",
    "\n",
    "            lstm_scope.reuse_variables()\n",
    "            sequence_len = tf.reduce_sum(self.caption_mask,1)\n",
    "            lstm_out, self.final_state = tf.nn.dynamic_rnn(cell=lstm_cell,\n",
    "                                              inputs = self.word_embedding,\n",
    "                                              sequence_length = sequence_len,\n",
    "                                              initial_state = self.initial_state,\n",
    "                                              dtype = tf.float32,\n",
    "                                              scope = lstm_scope)\n",
    "        #to stack batches vertically\n",
    "        lstm_out = tf.reshape(lstm_out, [-1, lstm_cell.output_size])\n",
    "\n",
    "        with tf.variable_scope(\"logits\") as logits_scope:\n",
    "            #w = tf.get_variable('w', [lstm_cell.output_size, self.config.vocab_size], initializer=self.initializer)\n",
    "            #b = tf.get_variable('b', [self.config.vocab_size], initializer=tf.constant_initializer(0.0))\n",
    "            # (Nt)*H ,H*v =Nt.V, bias is zero\n",
    "            #tf.summary.histogram(\"weights\", w)\n",
    "            #logits = tf.matmul(lstm_out,w)+b\n",
    "            #variable_summaries(w)\n",
    "            logits = tf.contrib.layers.fully_connected(\n",
    "                inputs = lstm_out,\n",
    "                num_outputs = self.config.vocab_size,\n",
    "                activation_fn = None,\n",
    "                weights_initializer = self.initializer,\n",
    "                scope = logits_scope\n",
    "            )\n",
    "            print(logits.get_shape())\n",
    "\n",
    "        with tf.variable_scope(\"loss\"):\n",
    "            #if self.mode == 'train':\n",
    "            targets = tf.reshape(self.caption_out,[-1])\n",
    "            mask = tf.to_float(tf.reshape(self.caption_mask,[-1]))\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=targets,\n",
    "                                                     logits = logits)\n",
    "            #loss = tf.reshape(loss,[loss.get_shape()[0],1])\n",
    "            #loss = np.reshape(loss, (loss.shape[0],1))\n",
    "            print(loss.get_shape())\n",
    "            batch_loss = tf.div(tf.reduce_sum(tf.multiply(loss, mask)),\n",
    "                                tf.reduce_sum(mask),\n",
    "                                name=\"batch_loss\")\n",
    "            tf.losses.add_loss(batch_loss)\n",
    "            self.total_loss = tf.losses.get_total_loss()\n",
    "            print(self.total_loss.get_shape())\n",
    "            #if self.mode == 'evaluation':\n",
    "            self.preds = tf.argmax(logits, 1)\n",
    "            \n",
    "    def _create_summaries(self):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            tf.summary.scalar(\"train-loss\", self.total_loss)\n",
    "            tf.summary.histogram(\"histogramforloss\", self.total_loss)\n",
    "            # because you have several summaries, we should merge them all\n",
    "            # into one op to make it easier to manage\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "            \n",
    "\n",
    "    def build_graph(self):\n",
    "        #tf.reset_default_graph()\n",
    "        self._build_embedding()\n",
    "        self._build_model()\n",
    "        self._create_summaries()\n",
    "\n",
    "def train_model(model, config, data):\n",
    "    \n",
    "    #g = tf.Graph()\n",
    "    #with g.as_default():\n",
    "    ################define optimizer########\n",
    "    num_batches = config.total_instances/config.batch_size\n",
    "    decay_steps = int(num_batches*config.num_epochs_per_decay)\n",
    "    learning_rate = tf.constant(config.initial_learning_rate)\n",
    "\n",
    "    learning_rate_decay_fn = None\n",
    "    def _decay_fn(learning_rate, global_step):\n",
    "        return tf.train.exponential_decay(learning_rate,\n",
    "                                         global_step,\n",
    "                                         decay_steps = decay_steps,\n",
    "                                         decay_rate=0.5,\n",
    "                                         staircase=True)\n",
    "\n",
    "    learning_rate_decay_fn = _decay_fn\n",
    "    train_op = tf.contrib.layers.optimize_loss(loss=model.total_loss,\n",
    "                                              global_step = model.global_step,\n",
    "                                              learning_rate = learning_rate,\n",
    "                                              optimizer = 'SGD',\n",
    "                                              clip_gradients = config.clip_gradients,\n",
    "                                              learning_rate_decay_fn =learning_rate_decay_fn)\n",
    "\n",
    "    ##################\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # if checkpoint exist, restore\n",
    "        #ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "        #if ckpt and ckpt.model_checkpoint_path:\n",
    "        #    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "\n",
    "        \n",
    "        # 100 epoch\n",
    "        total_runs = int((config.total_instances/config.batch_size)*config.num_epochs)\n",
    "        initial_step = model.global_step.eval()\n",
    "        \n",
    "        ### initialize summary writer\n",
    "        learning_change = tf.summary.scalar(\"learing_rate\", learning_rate)\n",
    "        #a = tf.summary.merge_all()\n",
    "        \n",
    "        writer = tf.summary.FileWriter('./graphs/singlelayer_lstm', sess.graph)\n",
    "        writer_tzr_handsome = tf.summary.FileWriter('./graphs/eval/singlelayer_lstm_eval', sess.graph)\n",
    "        time_now = datetime.now()\n",
    "        for t in range(total_runs):\n",
    "\n",
    "            caption_in, caption_out, mask, image_features, urls = minibatch(data,t,config.batch_size, config.total_instances)\n",
    "            \n",
    "            # feed data\n",
    "            feed_dict = {model.image_feature: image_features, model.caption_in: caption_in, \n",
    "                        model.caption_out: caption_out, model.caption_mask: mask}\n",
    "            merge_op, _, total_loss, learning = sess.run([model.summary_op, train_op, model.total_loss, learning_change],\n",
    "                                           feed_dict = feed_dict)\n",
    "\n",
    "            writer.add_summary(merge_op, global_step=t)\n",
    "            writer.add_summary(learning, global_step=t)\n",
    "            \n",
    "            # print loss infor\n",
    "            if(t+1) % 20 == 0:\n",
    "                print('(Iteration %d / %d) loss: %f, and time eclipsed: %.2f minutes' % (\n",
    "                    t + 1, total_runs, float(total_loss), (datetime.now() - time_now).seconds/60.0))\n",
    "            \n",
    "            #validation loss and generate captions\n",
    "            if(t+1)%10 == 0 or t ==(total_runs-1):\n",
    "                if not os.path.exists('test_caption'):\n",
    "                    os.makedirs('test_caption')\n",
    "                captions_pred, val_loss, sum_op = _run_validation(sess, caption_in, caption_out, image_features, config.batch_size, model, config.input_len) # the output is size (32, 16)\n",
    "                captions_pred = [unpack.reshape(-1, 1) for unpack in captions_pred]\n",
    "                captions_pred = np.concatenate(captions_pred, 1)\n",
    "                captions_deco = decode_captions(captions_pred, data['idx_to_word'])\n",
    "#                 for j in range(len(captions_deco)):\n",
    "#                     img_name = os.path.join('test_caption', 'image_{}.jpg'.format(j))\n",
    "#                     img = image_from_url(urls[j])\n",
    "#                     write_text_on_image(img, img_name, captions_deco[j])\n",
    "\n",
    "                add_val = sess.run(sum_op)\n",
    "                writer_tzr_handsome.add_summary(add_val, global_step = t)\n",
    "                \n",
    "\n",
    "            #save model\n",
    "            if(t+1)%50 == 0 or t == (total_runs-1):\n",
    "                if not os.path.exists('checkpoints/singlelayer_lstm'):\n",
    "                    os.makedirs('checkpoints/singlelayer_lstm')\n",
    "                saver.save(sess, 'checkpoints/singlelayer_lstm', t)\n",
    "        \n",
    "        # visualize embed matrix\n",
    "        #code to visualize the embeddings. uncomment the below to visualize embeddings\n",
    "        final_embed_matrix = sess.run(model.embed_map)\n",
    "        \n",
    "        # it has to variable. constants don't work here. you can't reuse model.embed_matrix\n",
    "        embedding_var = tf.Variable(final_embed_matrix[:1000], name='embedding')\n",
    "        sess.run(embedding_var.initializer)\n",
    "\n",
    "        config = projector.ProjectorConfig()\n",
    "        summary_writer = tf.summary.FileWriter('processed')\n",
    "\n",
    "        # add embedding to the config file\n",
    "        embedding = config.embeddings.add()\n",
    "        embedding.tensor_name = embedding_var.name\n",
    "        \n",
    "        # link this tensor to its metadata file, in this case the first 500 words of vocab\n",
    "#         metadata_path = './processed/matadata.tsv'\n",
    "#         if not os.path.exists(metadata_path):\n",
    "#             f = open(metadata_path, \"w\")\n",
    "#             f.close()\n",
    "        embedding.metadata_path = os.path.join('processed', 'metadata.tsv')\n",
    "\n",
    "        # saves a configuration file that TensorBoard will read during startup.\n",
    "        projector.visualize_embeddings(summary_writer, config)\n",
    "        saver_embed = tf.train.Saver([embedding_var])\n",
    "        saver_embed.save(sess, 'processed/model3.ckpt', 1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = Config()\n",
    "    data = load_coco_data()\n",
    "    model = LSTM_Model('train', config)\n",
    "    model.build_graph()\n",
    "    train_model(model, config, data)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
